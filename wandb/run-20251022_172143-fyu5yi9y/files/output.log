Epoch 0, iter 0, loss: 2.2876200675964355
Epoch 0, iter 100, loss: 0.747982919216156
Epoch 0, iter 200, loss: 1.0800758600234985
Epoch 0, iter 300, loss: 0.596977174282074
Epoch 0, iter 400, loss: 0.3341235816478729
Epoch 0, iter 500, loss: 1.6777793169021606
Epoch 0, iter 600, loss: 0.5926926136016846
Epoch 0, iter 700, loss: 0.29481807351112366
Epoch 0, iter 800, loss: 0.1509719043970108
Epoch 0, iter 900, loss: 0.18771833181381226
Epoch 1, iter 0, loss: 0.3372463583946228
Epoch 1, iter 100, loss: 0.20626696944236755
Epoch 1, iter 200, loss: 0.5491666793823242
Epoch 1, iter 300, loss: 0.4045032858848572
Epoch 1, iter 400, loss: 0.17133712768554688
Epoch 1, iter 500, loss: 0.8539050817489624
Epoch 1, iter 600, loss: 0.2927955389022827
Epoch 1, iter 700, loss: 0.08730392158031464
Epoch 1, iter 800, loss: 0.050038158893585205
Epoch 1, iter 900, loss: 0.056801505386829376
Epoch 2, iter 0, loss: 0.2962348163127899
Epoch 2, iter 100, loss: 0.24649578332901
Epoch 2, iter 200, loss: 0.5248835682868958
Epoch 2, iter 300, loss: 0.24831463396549225
Epoch 2, iter 400, loss: 0.21139086782932281
Epoch 2, iter 500, loss: 0.5547960996627808
Epoch 2, iter 600, loss: 0.11789090931415558
Epoch 2, iter 700, loss: 0.1417859047651291
Epoch 2, iter 800, loss: 0.032378654927015305
Epoch 2, iter 900, loss: 0.02067195437848568
/Users/francescocentomo/anaconda3/envs/MLOPS_p1/lib/python3.12/site-packages/sklearn/utils/_plotting.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  _, ax = plt.subplots()
Epoch 3, iter 0, loss: 0.11090900003910065
Epoch 3, iter 100, loss: 0.08138927072286606
Epoch 3, iter 200, loss: 0.4534614682197571
Epoch 3, iter 300, loss: 0.1913183629512787
Epoch 3, iter 400, loss: 0.10133842378854752
Epoch 3, iter 500, loss: 0.5012943148612976
Epoch 3, iter 600, loss: 0.1958211362361908
Epoch 3, iter 700, loss: 0.03342054784297943
Epoch 3, iter 800, loss: 0.01711561717092991
Epoch 3, iter 900, loss: 0.06912872195243835
Epoch 4, iter 0, loss: 0.05605441331863403
Epoch 4, iter 100, loss: 0.1331617385149002
Epoch 4, iter 200, loss: 0.1367248147726059
Epoch 4, iter 300, loss: 0.13956762850284576
Epoch 4, iter 400, loss: 0.3799159526824951
Epoch 4, iter 500, loss: 0.331013560295105
Epoch 4, iter 600, loss: 0.1714348942041397
Epoch 4, iter 700, loss: 0.031358879059553146
Epoch 4, iter 800, loss: 0.01017245277762413
Epoch 4, iter 900, loss: 0.009351126849651337
